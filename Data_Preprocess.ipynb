{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocess.ipynb",
      "provenance": [],
      "mount_file_id": "1MLz2zzenJJu1XaVijsx3xexFatIFuwLU",
      "authorship_tag": "ABX9TyPAyo+x9hRPt9nfJnA+o9vc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazann/Text-Generation/blob/main/Data_Preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak3eOn2SPh3i",
        "outputId": "96aeffe1-e27a-443b-b846-249fb42ba31a"
      },
      "source": [
        "!pip install git-python==1.0.3\r\n",
        "\r\n",
        "import os\r\n",
        "import csv\r\n",
        "import json\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import gc\r\n",
        "from dataclasses import dataclass, field\r\n",
        "from typing import Optional\r\n",
        "from getpass import getpass"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: git-python==1.0.3 in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from git-python==1.0.3) (3.1.14)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->git-python==1.0.3) (4.0.5)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python==1.0.3) (3.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viYT1HU6ypEh"
      },
      "source": [
        "Getting the data into a dataframe.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy8F8TvBu3Ww"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive\")\r\n",
        "\r\n",
        "!cp ChatExport_2021-01-01.zip /content\r\n",
        "\r\n",
        "os.chdir(\"/content\")\r\n",
        "\r\n",
        "!unzip ChatExport_2021-01-01.zip\r\n",
        "!rm ChatExport_2021-01-01.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X4TFs9OvmKB"
      },
      "source": [
        "f = open('ChatExport_2021-01-01/result.json',encoding=\"utf8\") \r\n",
        "messages = json.load(f)\r\n",
        "\r\n",
        "orig_df = pd.DataFrame(columns = [\"Writer\",\"Messages\",\"Date\"])\r\n",
        "i = 0\r\n",
        "\r\n",
        "for message in messages[\"messages\"]:\r\n",
        "    if message[\"type\"] == \"message\":\r\n",
        "        orig_df = orig_df.append({\r\n",
        "            \"Writer\":message[\"from\"],\r\n",
        "            \"Messages\":message[\"text\"],\r\n",
        "            \"Date\":message[\"date\"]\r\n",
        "                  }, ignore_index = True)\r\n",
        "        if i%100 == 0:\r\n",
        "            print(i)\r\n",
        "        i += 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnTVKT4Oy-NB"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXdEgnyjvpPa",
        "outputId": "effb8a02-4265-4965-e330-0da59d3c0d24"
      },
      "source": [
        "data_df = orig_df\r\n",
        "\r\n",
        "data_df[\"Writer\"] = np.where(data_df[\"Writer\"].isna(), \"Aykut\", data_df[\"Writer\"])\r\n",
        "\r\n",
        "data_df[\"Messages_Lower\"] = data_df[\"Messages\"].str.lower()\r\n",
        "data_df[\"Messages_Lower\"] = data_df[\"Messages_Lower\"].str.strip()\r\n",
        "data_df[\"Word_Splits\"] = data_df[\"Messages_Lower\"].str.split()\r\n",
        "\r\n",
        "data_df = data_df.dropna()\r\n",
        "\r\n",
        "data_df[\"Messages\"] = data_df[\"Messages_Lower\"]\r\n",
        "\r\n",
        "data_df = data_df.drop(\"Messages_Lower\", axis = 1)\r\n",
        "\r\n",
        "data_df = data_df.loc[data_df[\"Messages\"] != \"\"]\r\n",
        "\r\n",
        "writers = [\"Mert Yazan\", \"Kumru\", \"Atamert\", \"Abidin Dekar\", \"Aykut\"]\r\n",
        "\r\n",
        "data_df = data_df.loc[data_df[\"Writer\"].isin(writers)]\r\n",
        "\r\n",
        "i = 0\r\n",
        "data_lengths = []\r\n",
        "msg_words = data_df[\"Word_Splits\"].values\r\n",
        "\r\n",
        "while i < len(msg_words):\r\n",
        "    data_lengths.append(len(msg_words[i]))        \r\n",
        "    i += 1 \r\n",
        "    \r\n",
        "data_df[\"Lengths\"] = data_lengths    \r\n",
        "\r\n",
        "data_df = data_df.loc[data_df[\"Lengths\"] >= 1]\r\n",
        "\r\n",
        "data_df[\"Messages\"] = np.where((data_df[\"Messages\"].str.contains(\"hahaha\")) & (data_df[\"Lengths\"] == 1),\"hahaha\",data_df[\"Messages\"])\r\n",
        "\r\n",
        "data_df[\"Writer\"] = np.where(data_df[\"Writer\"] == \"Mert Yazan\", \"Mert\", data_df[\"Writer\"])\r\n",
        "data_df[\"Writer\"] = np.where(data_df[\"Writer\"] == \"Abidin Dekar\", \"Abidin\", data_df[\"Writer\"])\r\n",
        "\r\n",
        "data_df[\"input\"] = data_df[\"Writer\"] + \" \" + data_df[\"Messages\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFBLSqCezRVV"
      },
      "source": [
        "Creating the labels as the next sentences, and splitting them into train and val sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JbUM5lurVYv"
      },
      "source": [
        "label_len = len(data_df[\"input\"].values)-1\r\n",
        "\r\n",
        "data = []\r\n",
        "labels = []\r\n",
        "text = \"\"\r\n",
        "\r\n",
        "for i in range(label_len):\r\n",
        "  labels.append(data_df[\"input\"].values[i+1])\r\n",
        "  for j in range (1):\r\n",
        "    text = text + \" \" + data_df[\"input\"].values[i+j] \r\n",
        "  data.append(text)\r\n",
        "  text = \"\"\r\n",
        "\r\n",
        "labels = np.asarray(labels)\r\n",
        "data = np.asarray(data)\r\n",
        "\r\n",
        "df2 = pd.DataFrame()\r\n",
        "\r\n",
        "df2[\"Written_Text\"] = data\r\n",
        "df2[\"Answer_Text\"] = labels\r\n",
        "\r\n",
        "train, val = train_test_split(df2, test_size = 0.2)\r\n",
        "\r\n",
        "train.to_csv(\"telegram_chatbot_train.csv\", index = False, encoding = \"utf-8\")\r\n",
        "\r\n",
        "val.to_csv(\"telegram_chatbot_val.csv\", index = False, encoding = \"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}