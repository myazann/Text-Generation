{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate_Conversation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18SykIMUd8Fd0W52hFvp10aMKXqXBWEME",
      "authorship_tag": "ABX9TyNytFQuqDm+5t0exQWUNOTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazann/Text-Generation/blob/main/Generate_Conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEb99rEhk5Ty"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install datasets==1.0.2\r\n",
        "\r\n",
        "!pip install git-python==1.0.3\r\n",
        "! pip install tokenizers\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from transformers import OpenAIGPTLMHeadModel, Trainer, TrainingArguments, GPT2LMHeadModel\r\n",
        "from transformers import AutoModel, AutoModelWithLMHead, AutoTokenizer, EncoderDecoderModel, BertTokenizer\r\n",
        "from transformers import TextDataset,DataCollatorForLanguageModeling,LineByLineTextDataset\r\n",
        "from transformers import pipeline\r\n",
        "import torch\r\n",
        "import gc\r\n",
        "import datasets\r\n",
        "from dataclasses import dataclass, field\r\n",
        "from typing import Optional\r\n",
        "from tokenizers import BertWordPieceTokenizer, Tokenizer\r\n",
        "from tokenizers.processors import BertProcessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k27YTlpMlfU-"
      },
      "source": [
        "Loading data, tokenizer and the model.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHQcSQvcelOH",
        "outputId": "b61ee54d-2e00-4f7e-95ca-57c78a05d4f7"
      },
      "source": [
        "if os.listdir(\"/content/drive/My Drive/enc2dec\"):\r\n",
        "  last_trained_path = \"/content/drive/My Drive/enc2dec\" + \"/\" + os.listdir(\"/content/drive/My Drive/enc2dec\")[0]\r\n",
        "else:\r\n",
        "  last_trained_path = None \r\n",
        "\r\n",
        "tg_data_train = datasets.load_dataset(\"csv\", data_files = \"/content/drive/My Drive/telegram_chatbot_train.csv\", split = \"train\")\r\n",
        "tg_data_val = datasets.load_dataset(\"csv\", data_files = \"/content/drive/My Drive/telegram_chatbot_val.csv\", split = \"train\")\r\n",
        "\r\n",
        "\r\n",
        "tokenizer = AutoTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', do_lower_case=True, return_special_tokens_mask=True)\r\n",
        "tokenizer.bos_token = tokenizer.cls_token\r\n",
        "tokenizer.eos_token = tokenizer.sep_token\r\n",
        "\r\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"dbmdz/bert-base-turkish-cased\", \"dbmdz/bert-base-turkish-cased\")\r\n",
        "\r\n",
        "if last_trained_path is not None:\r\n",
        "  model = model.from_pretrained(last_trained_path).cuda()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-52f8e7c0f5270178/0.0.0/0d06ce3712951dae7909fb214283b88efab3578535edb5eebd37c498b7a35277)\n",
            "Using custom data configuration default\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-36c2692e7da1159c/0.0.0/0d06ce3712951dae7909fb214283b88efab3578535edb5eebd37c498b7a35277)\n",
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1Y9pWA7d-Xd"
      },
      "source": [
        "Sample code to generate text given an input. Different decoding strategies can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0cpIWv-KV5Y"
      },
      "source": [
        "start = tokenizer(\"aykut mert\", return_tensors=\"pt\").input_ids\r\n",
        "out = model.generate(start.cuda(), min_length = 5, max_length = 150, \r\n",
        "                     \r\n",
        "                    ## top k-sampling\r\n",
        "                    ##top_k = 50, do_sample = True  \r\n",
        "                     \r\n",
        "                    ## top p-sampling\r\n",
        "                    ##top_p = 0.95, do_sample = True \r\n",
        "\r\n",
        "                    #beam search\r\n",
        "                    no_repeat_ngram_size = 3, early_stopping=True, num_beams = 4, length_penalty = 2.0,\r\n",
        "\r\n",
        "                    temperature=0.95,\r\n",
        "                    ##num_return_sequences = 3\r\n",
        "                     )\r\n",
        "\r\n",
        "decoded = tokenizer.batch_decode(out)[0].split()\r\n",
        "kisi = decoded[1]\r\n",
        "msg = decoded[2:-1]\r\n",
        "\r\n",
        "kisi + \":\" + \" \".join(([str(elem) for elem in msg]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yiwa84waNSe"
      },
      "source": [
        "Start a conversation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toPN1dT0F1cs"
      },
      "source": [
        "i = 0\r\n",
        "start_sentence = input()\r\n",
        "\r\n",
        "while i < 25:\r\n",
        "\r\n",
        "  start = tokenizer(start_sentence, return_tensors=\"pt\").input_ids\r\n",
        "  out = model.generate(start.cuda(),  min_length = 5, max_length = 150,\r\n",
        "                      no_repeat_ngram_size = 3, early_stopping=True, num_beams = 4, length_penalty = 2.0,\r\n",
        "                      temperature=0.75)\r\n",
        "  \r\n",
        "\r\n",
        "  decoded = tokenizer.batch_decode(out)[0]\r\n",
        "\r\n",
        "  kisi = decoded.split()[1]\r\n",
        "  msg = decoded.split()[2:-1]\r\n",
        "\r\n",
        "  print(kisi + \":\" + \" \".join(([str(elem) for elem in msg])))\r\n",
        "  start_sentence = decoded\r\n",
        "\r\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}